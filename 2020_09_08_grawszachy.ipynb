{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2020-09-08-grawszachy.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MichalRyszardWojcik/hello-world/blob/master/2020_09_08_grawszachy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7qkcANh3Xnz",
        "colab_type": "text"
      },
      "source": [
        "# Section 0: Import and Install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMmztiOqenFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "! pip install -q -U trax\n",
        "import trax\n",
        "\n",
        "import chess\n",
        "import chess.pgn\n",
        "import chess.svg\n",
        "\n",
        "from IPython.core.display import HTML\n",
        "from IPython.display import Javascript"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBLzMkUL3p5R",
        "colab_type": "text"
      },
      "source": [
        "# Section 1: Python Chess vs Our Tokens and Chess GUI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c2MFNPJJU8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def move2token(move): return 64*move.from_square + move.to_square\n",
        "\n",
        "def token2move(token):\n",
        "  from_square = token // 64\n",
        "  to_square = token % 64\n",
        "  return chess.Move(from_square,to_square)\n",
        "\n",
        "def game2tokens(game):\n",
        "  tokens = []\n",
        "  line = game.main_line()\n",
        "  for move in line: tokens.append(move2token(move))\n",
        "  return tokens\n",
        "\n",
        "def tokens2board(tokens):\n",
        "  board = chess.Board()\n",
        "  for token in tokens:\n",
        "    move = token2move(token)\n",
        "    board.push(move)\n",
        "  return board\n",
        "\n",
        "def tokens2apronus(tokens):\n",
        "  moves = []\n",
        "  for token in tokens:\n",
        "    move = token2move(token).uci()\n",
        "    moves.append(move)\n",
        "  m = '_'.join(moves)\n",
        "  return 'https://www.apronus.com/chess/pgnviewer/?m=' + m\n",
        "\n",
        "def inputmoves_to_tokens(moves):\n",
        "  tokens = []\n",
        "  moves = moves.split('_')\n",
        "  for move in moves:\n",
        "    move = chess.Move.from_uci(move)\n",
        "    token = move2token(move)\n",
        "    tokens.append(token)\n",
        "  return tokens\n",
        "\n",
        "def displaygame(tokens):\n",
        "  print(tokens2apronus(tokens))\n",
        "  board = chess.Board()\n",
        "  html = ''\n",
        "  for x in tokens:\n",
        "    from_square = x//64\n",
        "    to_square = x % 64\n",
        "    move = chess.Move(from_square,to_square)\n",
        "    if (x == 0):\n",
        "      board.clear()\n",
        "      header = 'Game Over'\n",
        "    else:\n",
        "      legal = move in board.legal_moves\n",
        "      if legal:\n",
        "        legal = 'legal'\n",
        "        style = ''\n",
        "      else:\n",
        "        legal = 'illegal'\n",
        "        style = 'background:red; color:yellow; font-weight:bold;'\n",
        "      header = '<div style=\"'+style+'\">after '+legal+' '+move.uci()+'</div>'\n",
        "      board.push(move)\n",
        "    style = 'display:inline-block; width:20em; text-align:center; margin-bottom: 1em;'\n",
        "    html += '<div style=\"'+style+'\">'+header+chess.svg.board(board)+'</div>'\n",
        "  display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 5000})'''))\n",
        "  display(HTML(html))\n",
        "\n",
        "def usermove(board):\n",
        "  while True:\n",
        "    print('Type your move in UCI format:')\n",
        "    usermove = input()\n",
        "    if usermove == '': return ''\n",
        "    move = chess.Move.from_uci(usermove)\n",
        "    if move in board.legal_moves: return move;\n",
        "    print('You have typed an illegal move.')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmnPR14-5Xx1",
        "colab_type": "text"
      },
      "source": [
        "# Section 2: PGN Import and Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gs5Mww6m6808",
        "colab_type": "text"
      },
      "source": [
        "(1) We download the PGN file https://chessdiagram.online/games/lichess_db_standard_rated_2014-07.zip from my own server, originally taken from https://database.lichess.org/. It has almost a million games played by humans in July 2014 on Lichess. It is possible to get more games from there.\n",
        "\n",
        "(2) Next we tokenize this PGN file and save as \"/content/tokens1000k.txt\".\n",
        "\n",
        "(3) But tokenization takes a long time, longer than training a large model. Therefore, steps (1) and (2) are skipped by default (commented out) and instead we load the ready-made tokenized database from https://chessdiagram.online/games/tokens1000k.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4r_8hhpMPGAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g_max_ile = 1100*1000\n",
        "def tokenize(input_pgn_file,output_file):\n",
        "  ile = 0\n",
        "  while True:\n",
        "    game = chess.pgn.read_game(pgn)\n",
        "    if game == None: return ile\n",
        "    if len(game.errors) > 0: print(game.errors)\n",
        "    game = game2tokens(game)\n",
        "    if len(game) >= 24:\n",
        "      game = str(game).strip('[]')\n",
        "      output_file.write(game)\n",
        "      ile += 1\n",
        "      if ile % 1000 == 0: print(f'{ile//1000}K games tokenized')\n",
        "      if ile == g_max_ile:\n",
        "        output_file.close()\n",
        "        return ile\n",
        "      else:\n",
        "        output_file.write('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yXUgXMDxaHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget https://chessdiagram.online/games/lichess_db_standard_rated_2014-07.zip\n",
        "# !unzip lichess_db_standard_rated_2014-07.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pKqleQHQ8-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pgn = open('lichess_db_standard_rated_2014-07.pgn','r') # 1,048,440 games\n",
        "#tokens = open('/content/tokens1000k.txt','w')\n",
        "#ile = tokenize(pgn,tokens)\n",
        "#ile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yObJWYI0HDO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://chessdiagram.online/games/tokens1000k.zip\n",
        "!unzip tokens1000k.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QazVhAwffNdm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_tokenized_games(tokens_file):\n",
        "  tokenized_games = []\n",
        "  for line in tokens_file:\n",
        "    pregame = line.split(\", \")\n",
        "    game = []\n",
        "    for x in pregame:\n",
        "      game.append(int(x))\n",
        "    tokenized_games.append(game)\n",
        "  return tokenized_games"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk7huRehhtRB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tokens = open('/content/tokens.txt','r')\n",
        "tokens = open('tokens1000k.txt','r')\n",
        "tokenized_games = load_tokenized_games(tokens)\n",
        "ile = len(tokenized_games)\n",
        "print(ile) #979685 almost a million games"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc-blufs-qis",
        "colab_type": "text"
      },
      "source": [
        "The global variable <code>tokenized_games</code> is a list of tokenized games from the PGN database. It is used in the training process in the next section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xje_9Tv8_Jdt",
        "colab_type": "text"
      },
      "source": [
        "# Section 3: Training the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-si6NUnAPeO",
        "colab_type": "text"
      },
      "source": [
        "The training input is compoed of batches of random games. The batch size is **128 games** and the maximum game length is **60 half-moves**, which is 30 White moves and 30 Black moves."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y3N1GvdCkTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "game_length = 60\n",
        "g_vocab_size = 64*64"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0ogWE7yvNRf",
        "colab_type": "text"
      },
      "source": [
        "This section relies on the global variable <code>tokenized_games</code> prepared in the previous section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2F7lRFChMt_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g_ile = len(tokenized_games)\n",
        "def random_tokenized_game():\n",
        "  i = np.random.randint(0, g_ile)\n",
        "  return tokenized_games[i]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MksZemtPe_lv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training_input(batch_size, length):\n",
        "  while True:\n",
        "    shape = (batch_size,length)\n",
        "    games = np.zeros(shape, np.int32)\n",
        "    for y in range(batch_size):\n",
        "      game = random_tokenized_game()[0:length-1] # leaves a zero at the end\n",
        "      for x in range( min( len(game), length ) ):\n",
        "        games[y,x] = game[x]\n",
        "    inputs = games\n",
        "    targets = games\n",
        "    loss_weights = np.ones(shape, np.int32)\n",
        "    yield (inputs,targets,loss_weights)\n",
        "\n",
        "trax_inputs = trax.data.inputs.Inputs(lambda _: training_input(batch_size=128, length=game_length))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUIRKN-KxCBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perform_training(lm,n_epochs,train_steps,eval_steps):\n",
        "  output_dir = os.path.expanduser('~/train_dir/')\n",
        "  !rm -f ~/train_dir/model.pkl.gz  # Remove old model.\n",
        "  trainer = trax.supervised.Trainer(\n",
        "      model=lm,\n",
        "      loss_fn=trax.layers.CrossEntropyLoss(),\n",
        "      optimizer=trax.optimizers.Adafactor,  # Change optimizer params here.\n",
        "      lr_schedule=trax.lr.warmup_and_rsqrt_decay(400, 0.01),  # Change lr schedule here.\n",
        "      inputs=trax_inputs,\n",
        "      output_dir=output_dir)\n",
        "  for _ in range(n_epochs):\n",
        "    trainer.train_epoch(train_steps, eval_steps)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVqo6UDtewnH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Chess_transformer_lm_2020_09_04(mode='train'):\n",
        "  return trax.models.TransformerLM(  \n",
        "          d_model=128,\n",
        "          d_ff=256,\n",
        "          n_heads=2,\n",
        "          n_layers=2, \n",
        "          vocab_size= g_vocab_size,\n",
        "          mode=mode)\n",
        "\n",
        "def perform_training_2020_09_04():\n",
        "  perform_training(\n",
        "    lm=Chess_transformer_lm_2020_09_04,\n",
        "    n_epochs = 10,\n",
        "    train_steps = 500,\n",
        "    eval_steps = 2)\n",
        "\n",
        "perform_training_2020_09_04()\n",
        "model_2020_09_04 = ChessModel()\n",
        "model_2020_09_04.lm = Chess_transformer_lm_2020_09_04('predict')\n",
        "model_2020_09_04.path = '/root/train_dir/model.pkl.gz'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "073TTBzLz3Tl",
        "colab_type": "text"
      },
      "source": [
        "## Section 4.1: Training the stronger model (2090-09-07)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS6FfvT_0Mwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Chess_transformer_lm_2020_09_07(mode='train'):\n",
        "  return trax.models.TransformerLM(  \n",
        "        d_model=512,\n",
        "        d_ff=2048,\n",
        "        n_heads=4,\n",
        "        n_layers=8, \n",
        "        vocab_size= g_vocab_size,\n",
        "        mode=mode)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQYDsU2QnQrb",
        "colab_type": "text"
      },
      "source": [
        "The file https://chessdiagram.online/games/model-512-2048-4-8.pkl.gz contains a model trained in the following way:\n",
        "<pre><code>n_epochs = 10\n",
        "train_steps = 500\n",
        "eval_steps = 2\n",
        "\n",
        "Step    500: Ran 500 train steps in 346.33 secs\n",
        "Step    500: Evaluation\n",
        "Step    500: train                   accuracy |  0.30423179\n",
        "Step    500: train                       loss |  3.55055189\n",
        "Step    500: train         neg_log_perplexity | -3.55055189\n",
        "Step    500: train          sequence_accuracy |  0.00000000\n",
        "Step    500: train weights_per_batch_per_core |  7680.00000000\n",
        "Step    500: eval                    accuracy |  0.30260420\n",
        "Step    500: eval                        loss |  3.60096693\n",
        "Step    500: eval          neg_log_perplexity | -3.60096693\n",
        "Step    500: eval           sequence_accuracy |  0.00000000\n",
        "Step    500: eval  weights_per_batch_per_core |  7680.00000000\n",
        "Step    500: Finished evaluation\n",
        "\n",
        "Step   1000: Ran 500 train steps in 263.17 secs\n",
        "Step   1000: Evaluation\n",
        "Step   1000: train                   accuracy |  0.34700525\n",
        "Step   1000: train                       loss |  2.92200994\n",
        "Step   1000: train         neg_log_perplexity | -2.92200994\n",
        "Step   1000: train          sequence_accuracy |  0.00000000\n",
        "Step   1000: train weights_per_batch_per_core |  7680.00000000\n",
        "Step   1000: eval                    accuracy |  0.33118492\n",
        "Step   1000: eval                        loss |  2.99088240\n",
        "Step   1000: eval          neg_log_perplexity | -2.99088240\n",
        "Step   1000: eval           sequence_accuracy |  0.00000000\n",
        "Step   1000: eval  weights_per_batch_per_core |  7680.00000000\n",
        "Step   1000: Finished evaluation\n",
        "\n",
        "Step   1500: Ran 500 train steps in 264.86 secs\n",
        "Step   1500: Evaluation\n",
        "Step   1500: train                   accuracy |  0.35657555\n",
        "Step   1500: train                       loss |  2.74071789\n",
        "Step   1500: train         neg_log_perplexity | -2.74071789\n",
        "Step   1500: train          sequence_accuracy |  0.00000000\n",
        "Step   1500: train weights_per_batch_per_core |  7680.00000000\n",
        "Step   1500: eval                    accuracy |  0.37526044\n",
        "Step   1500: eval                        loss |  2.66420746\n",
        "Step   1500: eval          neg_log_perplexity | -2.66420746\n",
        "Step   1500: eval           sequence_accuracy |  0.00000000\n",
        "Step   1500: eval  weights_per_batch_per_core |  7680.00000000\n",
        "Step   1500: Finished evaluation\n",
        "\n",
        "Step   2000: Ran 500 train steps in 264.58 secs\n",
        "Step   2000: Evaluation\n",
        "Step   2000: train                   accuracy |  0.37539065\n",
        "Step   2000: train                       loss |  2.59341145\n",
        "Step   2000: train         neg_log_perplexity | -2.59341145\n",
        "Step   2000: train          sequence_accuracy |  0.00000000\n",
        "Step   2000: train weights_per_batch_per_core |  7680.00000000\n",
        "Step   2000: eval                    accuracy |  0.37265629\n",
        "Step   2000: eval                        loss |  2.59073925\n",
        "Step   2000: eval          neg_log_perplexity | -2.59073925\n",
        "Step   2000: eval           sequence_accuracy |  0.00000000\n",
        "Step   2000: eval  weights_per_batch_per_core |  7680.00000000\n",
        "Step   2000: Finished evaluation\n",
        "\n",
        "Step   2500: Ran 500 train steps in 263.33 secs\n",
        "Step   2500: Evaluation\n",
        "Step   2500: train                   accuracy |  0.38242191\n",
        "Step   2500: train                       loss |  2.50210452\n",
        "Step   2500: train         neg_log_perplexity | -2.50210452\n",
        "Step   2500: train          sequence_accuracy |  0.00000000\n",
        "Step   2500: train weights_per_batch_per_core |  7680.00000000\n",
        "Step   2500: eval                    accuracy |  0.38509119\n",
        "Step   2500: eval                        loss |  2.47769928\n",
        "Step   2500: eval          neg_log_perplexity | -2.47769928\n",
        "Step   2500: eval           sequence_accuracy |  0.00000000\n",
        "Step   2500: eval  weights_per_batch_per_core |  7680.00000000\n",
        "Step   2500: Finished evaluation\n",
        "\n",
        "Step   3000: Ran 500 train steps in 263.82 secs\n",
        "Step   3000: Evaluation\n",
        "Step   3000: train                   accuracy |  0.39967448\n",
        "Step   3000: train                       loss |  2.38351250\n",
        "Step   3000: train         neg_log_perplexity | -2.38351250\n",
        "Step   3000: train          sequence_accuracy |  0.00000000\n",
        "Step   3000: train weights_per_batch_per_core |  7680.00000000\n",
        "Step   3000: eval                    accuracy |  0.40162763\n",
        "Step   3000: eval                        loss |  2.38189268\n",
        "Step   3000: eval          neg_log_perplexity | -2.38189268\n",
        "Step   3000: eval           sequence_accuracy |  0.00000000\n",
        "Step   3000: eval  weights_per_batch_per_core |  7680.00000000\n",
        "Step   3000: Finished evaluation\n",
        "\n",
        "Step   3500: Ran 500 train steps in 262.57 secs\n",
        "Step   3500: Evaluation\n",
        "Step   3500: train                   accuracy |  0.40065107\n",
        "Step   3500: train                       loss |  2.35326505\n",
        "Step   3500: train         neg_log_perplexity | -2.35326505\n",
        "Step   3500: train          sequence_accuracy |  0.00000000\n",
        "Step   3500: train weights_per_batch_per_core |  7680.00000000\n",
        "Step   3500: eval                    accuracy |  0.39355472\n",
        "Step   3500: eval                        loss |  2.36699247\n",
        "Step   3500: eval          neg_log_perplexity | -2.36699247\n",
        "Step   3500: eval           sequence_accuracy |  0.00000000\n",
        "Step   3500: eval  weights_per_batch_per_core |  7680.00000000\n",
        "Step   3500: Finished evaluation\n",
        "\n",
        "Step   4000: Ran 500 train steps in 262.16 secs\n",
        "Step   4000: Evaluation\n",
        "Step   4000: train                   accuracy |  0.40716147\n",
        "Step   4000: train                       loss |  2.31738281\n",
        "Step   4000: train         neg_log_perplexity | -2.31738281\n",
        "Step   4000: train          sequence_accuracy |  0.00000000\n",
        "Step   4000: train weights_per_batch_per_core |  7680.00000000\n",
        "Step   4000: eval                    accuracy |  0.38880211\n",
        "Step   4000: eval                        loss |  2.41327047\n",
        "Step   4000: eval          neg_log_perplexity | -2.41327047\n",
        "Step   4000: eval           sequence_accuracy |  0.00000000\n",
        "Step   4000: eval  weights_per_batch_per_core |  7680.00000000\n",
        "Step   4000: Finished evaluation\n",
        "\n",
        "Step   4500: Ran 500 train steps in 261.18 secs\n",
        "Step   4500: Evaluation\n",
        "Step   4500: train                   accuracy |  0.39837241\n",
        "Step   4500: train                       loss |  2.30720091\n",
        "Step   4500: train         neg_log_perplexity | -2.30720091\n",
        "Step   4500: train          sequence_accuracy |  0.00000000\n",
        "Step   4500: train weights_per_batch_per_core |  7680.00000000\n",
        "Step   4500: eval                    accuracy |  0.40709639\n",
        "Step   4500: eval                        loss |  2.29545569\n",
        "Step   4500: eval          neg_log_perplexity | -2.29545569\n",
        "Step   4500: eval           sequence_accuracy |  0.00000000\n",
        "Step   4500: eval  weights_per_batch_per_core |  7680.00000000\n",
        "Step   4500: Finished evaluation\n",
        "\n",
        "Step   5000: Ran 500 train steps in 262.42 secs\n",
        "Step   5000: Evaluation\n",
        "Step   5000: train                   accuracy |  0.41028649\n",
        "Step   5000: train                       loss |  2.24561310\n",
        "Step   5000: train         neg_log_perplexity | -2.24561310\n",
        "Step   5000: train          sequence_accuracy |  0.00000000\n",
        "Step   5000: train weights_per_batch_per_core |  7680.00000000\n",
        "Step   5000: eval                    accuracy |  0.42076826\n",
        "Step   5000: eval                        loss |  2.22580862\n",
        "Step   5000: eval          neg_log_perplexity | -2.22580862\n",
        "Step   5000: eval           sequence_accuracy |  0.00000000\n",
        "Step   5000: eval  weights_per_batch_per_core |  7680.00000000\n",
        "Step   5000: Finished evaluation\n",
        "</code></pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWBLIAOt0z9c",
        "colab_type": "text"
      },
      "source": [
        "## Section 4.2: Downloading the stronger model (2020-09-07)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrQqLj3r3ibl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://chessdiagram.online/games/model-512-2048-4-8.pkl.gz\n",
        "\n",
        "# '/content/model-512-2048-4-8.pkl.gz'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPYqqkHZtsJu",
        "colab_type": "text"
      },
      "source": [
        "# Section 4: Testing the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aj6VSgI3MzNR",
        "colab_type": "text"
      },
      "source": [
        "We use three ways to interact with our chess playing models:\n",
        "1. <code>illegalgame(firstmoves,model,length)</code>\n",
        "<br>displays a game starting with <code>firstmoves</code> followed by <code>model</code>-generated (not necessarily) legal moves\n",
        "2. <code>legalgame(firstmoves,model,length)</code>\n",
        "<br>displays a game starting with <code>firstmoves</code> followed by <code>model</code>-generated legal moves\n",
        "3. <code>playchess(firstmoves,model)</code>\n",
        "<br>lets the user play against the <code>model</code> from the position after <code>firstmoves</code>\n",
        "\n",
        "The string <code>firstmoves</code> is a sequence of UCI formatted moves separated by the underscore, for example <code>firstmoves = 'f2f3_e7e5_g2g4_d8h4'</code>.\n",
        "\n",
        "The argument <code>model</code> is an object with two properties:\n",
        "1. <code>model.lm</code> is the result of calling <code>trax.models.TransformerLM(mode='predict')</code>\n",
        "2. <code>model.path</code> is the path to the model file \n",
        "\n",
        "Note that the argument <code>length</code>  is used to limit the number of half-moves outputted by the model.\n",
        "<br>It defaults to the global variable <code>game_length = 60</code>.\n",
        "\n",
        "These functions output the games as links to a chess editor,<br>\n",
        "for example https://www.apronus.com/chess/pgnviewer/?m=f2f3_e7e5_g2g4_d8h4\n",
        "<br>This allows us to view the games move by move on an interactive chessboard and to export them as PGN. The tails of these links can also be used as the input argument <code>firstmoves</code>.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf18innLckj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ChessModel():\n",
        "  lm = None\n",
        "  path = None\n",
        "\n",
        "model_2020_09_07 = ChessModel()\n",
        "model_2020_09_07.lm = trax.models.TransformerLM(d_model=512, d_ff=2048, n_heads=4, n_layers=8, vocab_size= g_vocab_size, mode='predict')\n",
        "model_2020_09_07.path = '/content/model-512-2048-4-8.pkl.gz'\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h86OCTeGvD0M",
        "colab_type": "text"
      },
      "source": [
        "The following two functions <code>autoregressive_sample_stream</code> and <code>autoregressive_sample</code><br>\n",
        "from https://github.com/google/trax/blob/master/trax/supervised/decoding.py\n",
        "<br>are modified to ensure that the model produces only legal chess moves."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lN3ltV4yUxP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from trax import layers as tl\n",
        "\n",
        "def autoregressive_sample_stream(model, inputs=None,\n",
        "                                 batch_size=1, temperature=1.0,\n",
        "                                 start_id=0, accelerate=True):\n",
        "  if inputs is not None and inputs.shape[0] != batch_size:\n",
        "    raise ValueError(f'Inputs batch size ({inputs.shape[0]}) does not match '\n",
        "                     f'batch_size arg ({batch_size}.')\n",
        "\n",
        "  fast_model = tl.Accelerate(model) if accelerate else model\n",
        "  start_symbol = np.full((batch_size, 1), start_id, dtype=np.int32)\n",
        "  if model.n_in == 1 and inputs is not None:\n",
        "    current_symbols = np.concatenate([start_symbol, inputs], axis=1)\n",
        "  else:\n",
        "    current_symbols = start_symbol\n",
        "\n",
        "  tokens = inputs.flatten()\n",
        "  board = tokens2board(tokens)\n",
        "\n",
        "  while True:\n",
        "    if model.n_in > 1 and inputs is not None:\n",
        "      logits = fast_model((inputs, current_symbols))[0]\n",
        "    else:\n",
        "      logits = fast_model(current_symbols)\n",
        "    #sample = tl.logsoftmax_sample(logits[:, -1, :], temperature=temperature)\n",
        "    x = logits[:, -1, :].flatten()\n",
        "    positive = np.exp(x)\n",
        "    legalmoves = board.legal_moves\n",
        "    for x in range(len(positive)):\n",
        "      if token2move(x) not in legalmoves:\n",
        "        positive[x] = 0\n",
        "    next_token = np.argmax(positive)\n",
        "    board.push(token2move(next_token))\n",
        "    sample = next_token\n",
        "    sample = np.array(sample).reshape((1,1))\n",
        "    yield sample\n",
        "    # NOTE: Because the model is autoregressive and in 'predict' mode, its\n",
        "    # history is cached in the model state and the next input is the single\n",
        "    # symbol just sampled.\n",
        "    current_symbols = sample[:, None]\n",
        "\n",
        "\n",
        "def autoregressive_sample(model, inputs=None,\n",
        "                          batch_size=1, temperature=1.0,\n",
        "                          start_id=0, eos_id=1, max_length=100,\n",
        "                          accelerate=True):\n",
        "  result = []\n",
        "  eos_seen = []\n",
        "  counter = 0\n",
        "  for sample in autoregressive_sample_stream(\n",
        "      model, inputs, batch_size=batch_size, temperature=temperature,\n",
        "      start_id=start_id, accelerate=accelerate):\n",
        "    sample = sample[:, None]\n",
        "    result.append(sample)\n",
        "    counter += 1\n",
        "    if counter >= max_length:\n",
        "      return np.concatenate(result, axis=1)\n",
        "    # Check at which batch positions have we already encountered EOS.\n",
        "    for j in range(batch_size):\n",
        "      if int(sample[j, 0]) == eos_id:\n",
        "        eos_seen.append(j)\n",
        "    # If EOS has been seen on all positions, stop.\n",
        "    if all([j in eos_seen for j in range(batch_size)]):\n",
        "      return np.concatenate(result, axis=1)\n",
        "  return np.concatenate(result, axis=1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX-nvztw6QLa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _displaygame(legal,firstmoves,model,length):\n",
        "  firstmoves = inputmoves_to_tokens(firstmoves)\n",
        "  board = tokens2board(firstmoves)\n",
        "  display(board)\n",
        "  input = np.array(firstmoves).reshape((1,len(firstmoves)))\n",
        "\n",
        "  print(f'Using model: {model.path}')\n",
        "  predict_model = model.lm\n",
        "  predict_signature = trax.shapes.ShapeDtype((1,1), dtype=np.int32)\n",
        "  predict_model.init_from_file(model.path,weights_only=True, input_signature=predict_signature)\n",
        "  if legal:\n",
        "    played =                          autoregressive_sample(predict_model, input, temperature=0.0, max_length=length, eos_id = 0)\n",
        "  else:\n",
        "    played = trax.supervised.decoding.autoregressive_sample(predict_model, input, temperature=0.0, max_length=length, eos_id = 0)\n",
        "\n",
        "  gamestart = input.flatten()\n",
        "  gameplayed = played.flatten()\n",
        "  game = np.concatenate((gamestart,gameplayed))\n",
        "  displaygame(game)\n",
        "\n",
        "def illegalgame(firstmoves,model,length=game_length):\n",
        "  _displaygame(False,firstmoves,model,length)\n",
        "def legalgame(firstmoves, model, length=game_length):\n",
        "  _displaygame(True,firstmoves,model,length)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX9YB1wYJWuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "illegalgame('e2e4_e7e5',model_2020_09_07,40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcWvK6Db0B8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "legalgame('e2e4_e7e5',model_2020_09_07,41)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyNiJkYFw5uK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _legal_token_after_tokens(firstmoves,model):\n",
        "  input = np.array(firstmoves).reshape((1,len(firstmoves)))\n",
        "  predict_model = model.lm\n",
        "  predict_signature = trax.shapes.ShapeDtype((1,1), dtype=np.int32)\n",
        "  predict_model.init_from_file(model.path,weights_only=True, input_signature=predict_signature)\n",
        "  return autoregressive_sample(predict_model, input, temperature=0.0, max_length=1, eos_id = 0)\n",
        "\n",
        "def playchess(moves,model):\n",
        "  board = chess.Board()\n",
        "  tokens = []\n",
        "  if moves != '':\n",
        "    moves = moves.split('_')\n",
        "    for move in moves:\n",
        "      move = chess.Move.from_uci(move)\n",
        "      board.push(move)\n",
        "      token = move2token(move)\n",
        "      tokens.append(token)\n",
        "  display(board)\n",
        "  while not board.is_game_over():\n",
        "    move = usermove(board)\n",
        "    if move == '': return\n",
        "    board.push(move)\n",
        "    display(board)\n",
        "    tokens.append(move2token(move))\n",
        "    if not board.is_game_over():\n",
        "      token = _legal_token_after_tokens(tokens,model)\n",
        "      token = token.flatten()[0]\n",
        "      tokens.append(token)\n",
        "      move = token2move(token)\n",
        "      board.push(move)\n",
        "      print(f'Using model: {model.path}')\n",
        "      display(board)\n",
        "      print(tokens2apronus(tokens))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpwAc1ItMJfX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "playchess('',model_2020_09_04)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr5YPUoy3T1o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "playchess('',model_2020_09_07)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvejyJkyOBZH",
        "colab_type": "text"
      },
      "source": [
        "# Section 5: Notes and observations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUK6r_9EcErb",
        "colab_type": "text"
      },
      "source": [
        "The weaker engine fails to capture the queen after<br>\n",
        "https://www.apronus.com/chess/pgnviewer/?m=e2e4_e7e5_f1c4_g8f6_d1h5_g7g6_b1c3_f8g7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UA4hP8PFYA6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "playchess('e2e4_e7e5_f1c4_g8f6',model_2020_09_04)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWv9il8kc6Yg",
        "colab_type": "text"
      },
      "source": [
        "The stronger model captured the queen at h5:<br>\n",
        "https://www.apronus.com/chess/pgnviewer/?m=e2e4_e7e5_f1c4_f8c5_b1c3_g8f6_d1h5_f6h5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etJvsmt3chII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "legalgame('e2e4_e7e5_f1c4_g8f6_d1h5',model_2020_09_07,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq8ITl_6M-tF",
        "colab_type": "text"
      },
      "source": [
        "(It played quite well despite leaving the bishop c5 unprotected and blundering the queen at h4:\n",
        "https://www.apronus.com/chess/pgnviewer/?m=e2e4_e7e5_f1c4_f8c5_b1c3_g8f6_d1h5_f6h5_g2g4_h5f4_c3a4_e8g8_a4c5_d7d6_a2a4_c8g4_c5e6_g4e6_c4f1_b8c6_a4a5_c6d4_h2h4_d4c2_e1d1_c2a1_a5a6_b7b6_b2b4_d8h4_h1h4_f7f5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_serjGmUuKAe",
        "colab_type": "text"
      },
      "source": [
        "The stronger model is much more interesting after 1.Nh3. The old model ignored this move and imitated a game with no regard to the knight having moved to h3. But the stronger model actually uses this knight to go to f7:\n",
        "https://www.apronus.com/chess/pgnviewer/?m=g1h3_e7e5_h3g5_d7d5_g5f7_e8f7_e2e3_g8f6_b1c3_f8b4_a2a3_b4c3_d2c3_e5e4_f1e2_h8e8_e1g1_f7g8_c1d2_c7c6_c3c4_c8e6_c4d5_c6d5_c2c4_b8c6_c4d5_e6d5_d2c3_d5d4_c3d2_d4e3_d2e3_e8e3_f2e3_e8e3_d1c2_c6d4_c2c3_d4e2_g1h1_e2g3_h2g3_f6e4_h1h2_g3f1_a1f1_e4g3_h2g3_f1g3_f1f4_g3f1_f4f1_g3f1_d1f1_g3f1_0000\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qfh6-VKPdTki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "legalgame('g1h3',model_2020_09_04,7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "003rIvORdavh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "legalgame('g1h3',model_2020_09_07,7)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
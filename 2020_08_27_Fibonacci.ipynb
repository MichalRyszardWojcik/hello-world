{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2020-08-27-Fibonacci.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMWtvF7L9zXeWM+Vj9kdCSP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MichalRyszardWojcik/hello-world/blob/master/2020_08_27_Fibonacci.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMmztiOqenFD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "outputId": "814fb79b-2bb0-4a3f-aa0c-b1ae8ff11db9"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "! pip install -q -U trax\n",
        "import trax"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 368kB 3.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.6MB 10.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 163kB 35.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.5MB 35.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.5MB 46.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 5.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 778kB 42.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 307kB 44.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 45.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 368kB 41.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.3MB 39.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 184kB 49.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 358kB 48.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 6.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 655kB 48.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 983kB 44.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 34.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.0MB 41.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 235kB 49.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 5.3MB/s \n",
            "\u001b[?25h  Building wheel for bz2file (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pypng (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "INFO:tensorflow:tokens_length=568 inputs_length=512 targets_length=114 noise_density=0.15 mean_noise_span_length=3.0 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ep8MWrUbVfR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Fibo(a1,a2,length):\n",
        "  #if length == 0: return []\n",
        "  #if length == 1: return [a1]\n",
        "  if length == 2: return [a1,a2]\n",
        "  a3 = a1+a2\n",
        "  return [a1] + Fibo(a2,a3,length-1)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5baCWRrxiRgU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def RandomFibos(batch_size, length, start):\n",
        "  seeds = np.random.randint(1, start, (batch_size,2))\n",
        "  Fibos = []\n",
        "  for i in range(batch_size):\n",
        "    a1 = seeds[i][0]\n",
        "    a2 = seeds[i][1]\n",
        "    if (a1 > a2): b = a1; a1 = a2; a2 = b\n",
        "    Fibos += Fibo(a1,a2,length)\n",
        "  return np.array(Fibos).reshape(batch_size,length)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIDuoeVbQwYj",
        "colab_type": "text"
      },
      "source": [
        "g_Fibolength = length of sequences generated as training input\n",
        "\n",
        "g_Fibostart = the maximum integer used in seeding random Fibonacci sequences (they are determined by the first two terms, this is the maximum second term)\n",
        "\n",
        "g_Fibolength = 10 and g_Fibostart = 74 are the maximum numbers so that vocab_size is slightly below 64x64 = 4096 - the number we need for the chess project\n",
        "\n",
        "Unfortunately, it is unrealistic to use these numbers because the training is either absurdly slow or absurdly inaccurate.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVqo6UDtewnH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "bc3210bc-14c6-4e7b-bb4a-e5e9b938d480"
      },
      "source": [
        "g_Fibolength = 7 #10\n",
        "g_Fibostart = 11 #74\n",
        "\n",
        "maxFibo = Fibo(g_Fibostart,g_Fibostart,g_Fibolength)\n",
        "print(f'maxFibo={maxFibo}')\n",
        "g_vocab_size = np.max(maxFibo) + 1\n",
        "print(f'vocab_size={g_vocab_size}')\n",
        "print(f'64x64={64*64}')\n",
        "\n",
        "def Fibo_transformer_lm(mode='train'):\n",
        "  return trax.models.TransformerLM(  \n",
        "          d_model=32,\n",
        "          d_ff=128,\n",
        "          n_layers=2, \n",
        "          vocab_size= g_vocab_size,\n",
        "          mode=mode)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "maxFibo=[11, 11, 22, 33, 55, 88, 143]\n",
            "vocab_size=144\n",
            "64x64=4096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MksZemtPe_lv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training_input(batch_size, length):\n",
        "  while True:\n",
        "    Fibos = RandomFibos(batch_size=batch_size, length=g_Fibolength, start=g_Fibostart)\n",
        "    inputs = Fibos\n",
        "    targets = Fibos\n",
        "    loss_weights = np.ones((batch_size, length), np.int32)\n",
        "    yield (inputs,targets,loss_weights)\n",
        "\n",
        "trax_inputs = trax.data.inputs.Inputs(lambda _: training_input(batch_size=16, length=g_Fibolength))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFYt8M7KvnFI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "9987ae36-eb57-4a39-c53d-5104699dd6df"
      },
      "source": [
        "next(training_input(7,g_Fibolength))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[  8,   8,  16,  24,  40,  64, 104],\n",
              "        [  2,   7,   9,  16,  25,  41,  66],\n",
              "        [  1,   1,   2,   3,   5,   8,  13],\n",
              "        [  4,   7,  11,  18,  29,  47,  76],\n",
              "        [  9,  10,  19,  29,  48,  77, 125],\n",
              "        [  4,   5,   9,  14,  23,  37,  60],\n",
              "        [  5,   9,  14,  23,  37,  60,  97]]),\n",
              " array([[  8,   8,  16,  24,  40,  64, 104],\n",
              "        [  2,   7,   9,  16,  25,  41,  66],\n",
              "        [  1,   1,   2,   3,   5,   8,  13],\n",
              "        [  4,   7,  11,  18,  29,  47,  76],\n",
              "        [  9,  10,  19,  29,  48,  77, 125],\n",
              "        [  4,   5,   9,  14,  23,  37,  60],\n",
              "        [  5,   9,  14,  23,  37,  60,  97]]),\n",
              " array([[1, 1, 1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 1, 1, 1]], dtype=int32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUIRKN-KxCBu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2e862a20-92ad-4c55-be50-52f22f641ca9"
      },
      "source": [
        "output_dir = os.path.expanduser('~/train_dir/')\n",
        "!rm -f ~/train_dir/model.pkl.gz  # Remove old model.\n",
        "\n",
        "# Train tiny model with Trainer.\n",
        "trainer = trax.supervised.Trainer(\n",
        "    model=Fibo_transformer_lm,\n",
        "    loss_fn=trax.layers.CrossEntropyLoss(),\n",
        "    optimizer=trax.optimizers.Adafactor,  # Change optimizer params here.\n",
        "    lr_schedule=trax.lr.constant(0.001),  # Change lr schedule here.\n",
        "    inputs=trax_inputs,\n",
        "    output_dir=output_dir)\n",
        "\n",
        "n_epochs  = 5\n",
        "train_steps = 500\n",
        "eval_steps = 2\n",
        "for _ in range(n_epochs):\n",
        "  trainer.train_epoch(train_steps, eval_steps)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Step    500: Ran 500 train steps in 66.62 secs\n",
            "Step    500: Evaluation\n",
            "Step    500: train                   accuracy |  0.45535713\n",
            "Step    500: train                       loss |  2.53289914\n",
            "Step    500: train         neg_log_perplexity | -2.53289914\n",
            "Step    500: train          sequence_accuracy |  0.00000000\n",
            "Step    500: train weights_per_batch_per_core |  112.00000000\n",
            "Step    500: eval                    accuracy |  0.45089287\n",
            "Step    500: eval                        loss |  2.52572608\n",
            "Step    500: eval          neg_log_perplexity | -2.52572608\n",
            "Step    500: eval           sequence_accuracy |  0.00000000\n",
            "Step    500: eval  weights_per_batch_per_core |  112.00000000\n",
            "Step    500: Finished evaluation\n",
            "\n",
            "Step   1000: Ran 500 train steps in 4.43 secs\n",
            "Step   1000: Evaluation\n",
            "Step   1000: train                   accuracy |  0.69196427\n",
            "Step   1000: train                       loss |  1.04891539\n",
            "Step   1000: train         neg_log_perplexity | -1.04891539\n",
            "Step   1000: train          sequence_accuracy |  0.00000000\n",
            "Step   1000: train weights_per_batch_per_core |  112.00000000\n",
            "Step   1000: eval                    accuracy |  0.57142860\n",
            "Step   1000: eval                        loss |  1.35262358\n",
            "Step   1000: eval          neg_log_perplexity | -1.35262358\n",
            "Step   1000: eval           sequence_accuracy |  0.00000000\n",
            "Step   1000: eval  weights_per_batch_per_core |  112.00000000\n",
            "Step   1000: Finished evaluation\n",
            "\n",
            "Step   1500: Ran 500 train steps in 4.55 secs\n",
            "Step   1500: Evaluation\n",
            "Step   1500: train                   accuracy |  0.70982146\n",
            "Step   1500: train                       loss |  0.81843895\n",
            "Step   1500: train         neg_log_perplexity | -0.81843895\n",
            "Step   1500: train          sequence_accuracy |  0.00000000\n",
            "Step   1500: train weights_per_batch_per_core |  112.00000000\n",
            "Step   1500: eval                    accuracy |  0.71875000\n",
            "Step   1500: eval                        loss |  0.77048326\n",
            "Step   1500: eval          neg_log_perplexity | -0.77048326\n",
            "Step   1500: eval           sequence_accuracy |  0.00000000\n",
            "Step   1500: eval  weights_per_batch_per_core |  112.00000000\n",
            "Step   1500: Finished evaluation\n",
            "\n",
            "Step   2000: Ran 500 train steps in 4.77 secs\n",
            "Step   2000: Evaluation\n",
            "Step   2000: train                   accuracy |  0.75000000\n",
            "Step   2000: train                       loss |  0.64949644\n",
            "Step   2000: train         neg_log_perplexity | -0.64949644\n",
            "Step   2000: train          sequence_accuracy |  0.00000000\n",
            "Step   2000: train weights_per_batch_per_core |  112.00000000\n",
            "Step   2000: eval                    accuracy |  0.72321427\n",
            "Step   2000: eval                        loss |  0.71700680\n",
            "Step   2000: eval          neg_log_perplexity | -0.71700680\n",
            "Step   2000: eval           sequence_accuracy |  0.03125000\n",
            "Step   2000: eval  weights_per_batch_per_core |  112.00000000\n",
            "Step   2000: Finished evaluation\n",
            "\n",
            "Step   2500: Ran 500 train steps in 4.69 secs\n",
            "Step   2500: Evaluation\n",
            "Step   2500: train                   accuracy |  0.76339287\n",
            "Step   2500: train                       loss |  0.61168176\n",
            "Step   2500: train         neg_log_perplexity | -0.61168176\n",
            "Step   2500: train          sequence_accuracy |  0.06250000\n",
            "Step   2500: train weights_per_batch_per_core |  112.00000000\n",
            "Step   2500: eval                    accuracy |  0.77232146\n",
            "Step   2500: eval                        loss |  0.62091064\n",
            "Step   2500: eval          neg_log_perplexity | -0.62091064\n",
            "Step   2500: eval           sequence_accuracy |  0.00000000\n",
            "Step   2500: eval  weights_per_batch_per_core |  112.00000000\n",
            "Step   2500: Finished evaluation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrQqLj3r3ibl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def output(input):\n",
        "  predict_model = Fibo_transformer_lm(mode='predict')\n",
        "  predict_signature = trax.shapes.ShapeDtype((1,1), dtype=np.int32)\n",
        "  predict_model.init_from_file(os.path.join(output_dir, \"model.pkl.gz\"),weights_only=True, input_signature=predict_signature)\n",
        "  return trax.supervised.decoding.autoregressive_sample(predict_model, input, temperature=0.0, max_length=g_Fibolength+3, eos_id = -1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5yMY-UE3slk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "50379780-d95e-41dd-fb63-547f4eda6aab"
      },
      "source": [
        "input = np.array([[1,1]])\n",
        "print(output(input))\n",
        "input = np.array([[2,2]])\n",
        "print(output(input))\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 3  5  8 13 21 34 55 89  3 89]]\n",
            "[[ 5  7 12 19 31 50 81  5  8 13]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9Pq2HYJ7hJI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "214f29a5-e303-48b9-873e-70f88944ee26"
      },
      "source": [
        "input = np.array([[3]])\n",
        "output(input)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 9, 12, 21, 33, 54, 87, 19, 29, 48, 77]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ap3Rk0mA6f0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "05bfd0a4-6ba6-4999-a086-fbfa5673938d"
      },
      "source": [
        "input = np.array([[3,3]])\n",
        "output(input)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 5,  8, 13, 21, 34, 55, 89, 28, 46, 74]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2020-09-04-grawszachy.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MichalRyszardWojcik/hello-world/blob/master/2020_09_04_grawszachy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMmztiOqenFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "! pip install -q -U trax\n",
        "import trax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aeaj9umQJLOc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import chess\n",
        "import chess.pgn\n",
        "import chess.svg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c2MFNPJJU8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def move2token(move): return 64*move.from_square + move.to_square\n",
        "\n",
        "def token2move(token):\n",
        "  from_square = token // 64\n",
        "  to_square = token % 64\n",
        "  return chess.Move(from_square,to_square)\n",
        "\n",
        "def game2tokens(game):\n",
        "  tokens = []\n",
        "  line = game.main_line()\n",
        "  for move in line: tokens.append(move2token(move))\n",
        "  return tokens\n",
        "\n",
        "def tokens2board(tokens):\n",
        "  board = chess.Board()\n",
        "  for x in tokens:\n",
        "    from_square = x//64\n",
        "    to_square = x % 64\n",
        "    move = chess.Move(from_square,to_square)\n",
        "    board.push(move)\n",
        "  return board"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yXUgXMDxaHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget https://chessdiagram.online/games/lichess_db_standard_rated_2014-07.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GqxWDMwx25V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !unzip lichess_db_standard_rated_2014-07.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4r_8hhpMPGAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g_max_ile = 1100*1000\n",
        "def tokenize(input_pgn_file,output_file):\n",
        "  ile = 0\n",
        "  while True:\n",
        "    game = chess.pgn.read_game(pgn)\n",
        "    if game == None: return ile\n",
        "    if len(game.errors) > 0: print(game.errors)\n",
        "    game = game2tokens(game)\n",
        "    if len(game) >= 24:\n",
        "      game = str(game).strip('[]')\n",
        "      output_file.write(game)\n",
        "      ile += 1\n",
        "      if ile % 1000 == 0: print(f'{ile//1000}K games tokenized')\n",
        "      if ile == g_max_ile:\n",
        "        output_file.close()\n",
        "        return ile\n",
        "      else:\n",
        "        output_file.write('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pKqleQHQ8-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pgn = open('lichess_db_standard_rated_2014-07.pgn','r') # 1,048,440 games\n",
        "#tokens = open('/content/tokens.txt','w')\n",
        "#ile = tokenize(pgn,tokens)\n",
        "#ile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yObJWYI0HDO7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "00b08e32-167e-43c5-e83f-dcfcb501be6e"
      },
      "source": [
        "!wget https://chessdiagram.online/games/tokens1000k.zip\n",
        "!unzip tokens1000k.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-04 16:39:44--  https://chessdiagram.online/games/tokens1000k.zip\n",
            "Resolving chessdiagram.online (chessdiagram.online)... 184.154.45.213\n",
            "Connecting to chessdiagram.online (chessdiagram.online)|184.154.45.213|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 110390368 (105M) [application/zip]\n",
            "Saving to: ‘tokens1000k.zip.1’\n",
            "\n",
            "tokens1000k.zip.1   100%[===================>] 105.28M  31.0MB/s    in 4.3s    \n",
            "\n",
            "2020-09-04 16:39:48 (24.3 MB/s) - ‘tokens1000k.zip.1’ saved [110390368/110390368]\n",
            "\n",
            "Archive:  tokens1000k.zip\n",
            "replace tokens1000k.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: tokens1000k.txt         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QazVhAwffNdm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_tokenized_games(tokens_file):\n",
        "  tokenized_games = []\n",
        "  for line in tokens_file:\n",
        "    pregame = line.split(\", \")\n",
        "    game = []\n",
        "    for x in pregame:\n",
        "      game.append(int(x))\n",
        "    tokenized_games.append(game)\n",
        "  return tokenized_games"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk7huRehhtRB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tokens = open('/content/tokens.txt','r')\n",
        "tokens = open('tokens1000k.txt')\n",
        "tokenized_games = load_tokenized_games(tokens)\n",
        "ile = len(tokenized_games)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1bAvouKCSLC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8d3589e0-b47c-477d-86ba-2534beb3f8f7"
      },
      "source": [
        "print(ile) #979685 almost a million games"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "979685\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2F7lRFChMt_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_tokenized_game():\n",
        "  # ile = len(tokenized_games)\n",
        "  i = np.random.randint(0, ile)\n",
        "  return tokenized_games[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MksZemtPe_lv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training_input(batch_size, length):\n",
        "  while True:\n",
        "    shape = (batch_size,length)\n",
        "    games = np.zeros(shape, np.int32)\n",
        "    for y in range(batch_size):\n",
        "      game = random_tokenized_game()[0:length-1] # leaves a zero at the end\n",
        "      for x in range( min( len(game), length ) ):\n",
        "        games[y,x] = game[x]\n",
        "    inputs = games\n",
        "    targets = games\n",
        "    loss_weights = np.ones(shape, np.int32)\n",
        "    yield (inputs,targets,loss_weights)\n",
        "\n",
        "game_length = 60 #40\n",
        "\n",
        "trax_inputs = trax.data.inputs.Inputs(lambda _: training_input(batch_size=128, length=game_length))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVqo6UDtewnH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Chess_transformer_lm(mode='train'):\n",
        "  return trax.models.TransformerLM(  \n",
        "          d_model=128,\n",
        "          d_ff=256,\n",
        "          n_heads=2,\n",
        "          n_layers=2, \n",
        "          vocab_size= g_vocab_size,\n",
        "          mode=mode)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUIRKN-KxCBu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "22965e4a-7979-4611-8944-4be2256821d1"
      },
      "source": [
        "g_vocab_size = 64*64\n",
        "\n",
        "output_dir = os.path.expanduser('~/train_dir/')\n",
        "!rm -f ~/train_dir/model.pkl.gz  # Remove old model.\n",
        "\n",
        "# Train tiny model with Trainer.\n",
        "trainer = trax.supervised.Trainer(\n",
        "    model=Chess_transformer_lm,\n",
        "    loss_fn=trax.layers.CrossEntropyLoss(),\n",
        "    optimizer=trax.optimizers.Adafactor,  # Change optimizer params here.\n",
        "    lr_schedule=trax.lr.warmup_and_rsqrt_decay(400, 0.01),  # Change lr schedule here.\n",
        "    inputs=trax_inputs,\n",
        "    output_dir=output_dir)\n",
        "\n",
        "n_epochs = 10\n",
        "train_steps = 500\n",
        "eval_steps = 2\n",
        "for _ in range(n_epochs):\n",
        "  trainer.train_epoch(train_steps, eval_steps)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Step    500: Ran 500 train steps in 29.31 secs\n",
            "Step    500: Evaluation\n",
            "Step    500: train                   accuracy |  0.24570315\n",
            "Step    500: train                       loss |  4.20872879\n",
            "Step    500: train         neg_log_perplexity | -4.20872879\n",
            "Step    500: train          sequence_accuracy |  0.00000000\n",
            "Step    500: train weights_per_batch_per_core |  7680.00000000\n",
            "Step    500: eval                    accuracy |  0.26087242\n",
            "Step    500: eval                        loss |  4.12316608\n",
            "Step    500: eval          neg_log_perplexity | -4.12316608\n",
            "Step    500: eval           sequence_accuracy |  0.00000000\n",
            "Step    500: eval  weights_per_batch_per_core |  7680.00000000\n",
            "Step    500: Finished evaluation\n",
            "\n",
            "Step   1000: Ran 500 train steps in 12.23 secs\n",
            "Step   1000: Evaluation\n",
            "Step   1000: train                   accuracy |  0.30423176\n",
            "Step   1000: train                       loss |  3.51331115\n",
            "Step   1000: train         neg_log_perplexity | -3.51331115\n",
            "Step   1000: train          sequence_accuracy |  0.00000000\n",
            "Step   1000: train weights_per_batch_per_core |  7680.00000000\n",
            "Step   1000: eval                    accuracy |  0.28020835\n",
            "Step   1000: eval                        loss |  3.65941811\n",
            "Step   1000: eval          neg_log_perplexity | -3.65941811\n",
            "Step   1000: eval           sequence_accuracy |  0.00000000\n",
            "Step   1000: eval  weights_per_batch_per_core |  7680.00000000\n",
            "Step   1000: Finished evaluation\n",
            "\n",
            "Step   1500: Ran 500 train steps in 12.26 secs\n",
            "Step   1500: Evaluation\n",
            "Step   1500: train                   accuracy |  0.29765627\n",
            "Step   1500: train                       loss |  3.41260242\n",
            "Step   1500: train         neg_log_perplexity | -3.41260242\n",
            "Step   1500: train          sequence_accuracy |  0.00000000\n",
            "Step   1500: train weights_per_batch_per_core |  7680.00000000\n",
            "Step   1500: eval                    accuracy |  0.30768231\n",
            "Step   1500: eval                        loss |  3.33681440\n",
            "Step   1500: eval          neg_log_perplexity | -3.33681440\n",
            "Step   1500: eval           sequence_accuracy |  0.00000000\n",
            "Step   1500: eval  weights_per_batch_per_core |  7680.00000000\n",
            "Step   1500: Finished evaluation\n",
            "\n",
            "Step   2000: Ran 500 train steps in 12.32 secs\n",
            "Step   2000: Evaluation\n",
            "Step   2000: train                   accuracy |  0.31315106\n",
            "Step   2000: train                       loss |  3.24034595\n",
            "Step   2000: train         neg_log_perplexity | -3.24034595\n",
            "Step   2000: train          sequence_accuracy |  0.00000000\n",
            "Step   2000: train weights_per_batch_per_core |  7680.00000000\n",
            "Step   2000: eval                    accuracy |  0.32773441\n",
            "Step   2000: eval                        loss |  3.15924191\n",
            "Step   2000: eval          neg_log_perplexity | -3.15924191\n",
            "Step   2000: eval           sequence_accuracy |  0.00000000\n",
            "Step   2000: eval  weights_per_batch_per_core |  7680.00000000\n",
            "Step   2000: Finished evaluation\n",
            "\n",
            "Step   2500: Ran 500 train steps in 12.39 secs\n",
            "Step   2500: Evaluation\n",
            "Step   2500: train                   accuracy |  0.32734376\n",
            "Step   2500: train                       loss |  3.08897734\n",
            "Step   2500: train         neg_log_perplexity | -3.08897734\n",
            "Step   2500: train          sequence_accuracy |  0.00000000\n",
            "Step   2500: train weights_per_batch_per_core |  7680.00000000\n",
            "Step   2500: eval                    accuracy |  0.32324219\n",
            "Step   2500: eval                        loss |  3.09914255\n",
            "Step   2500: eval          neg_log_perplexity | -3.09914255\n",
            "Step   2500: eval           sequence_accuracy |  0.00000000\n",
            "Step   2500: eval  weights_per_batch_per_core |  7680.00000000\n",
            "Step   2500: Finished evaluation\n",
            "\n",
            "Step   3000: Ran 500 train steps in 12.42 secs\n",
            "Step   3000: Evaluation\n",
            "Step   3000: train                   accuracy |  0.31601563\n",
            "Step   3000: train                       loss |  3.13145781\n",
            "Step   3000: train         neg_log_perplexity | -3.13145781\n",
            "Step   3000: train          sequence_accuracy |  0.00000000\n",
            "Step   3000: train weights_per_batch_per_core |  7680.00000000\n",
            "Step   3000: eval                    accuracy |  0.33372396\n",
            "Step   3000: eval                        loss |  3.02499270\n",
            "Step   3000: eval          neg_log_perplexity | -3.02499270\n",
            "Step   3000: eval           sequence_accuracy |  0.00000000\n",
            "Step   3000: eval  weights_per_batch_per_core |  7680.00000000\n",
            "Step   3000: Finished evaluation\n",
            "\n",
            "Step   3500: Ran 500 train steps in 12.47 secs\n",
            "Step   3500: Evaluation\n",
            "Step   3500: train                   accuracy |  0.33567709\n",
            "Step   3500: train                       loss |  2.99213839\n",
            "Step   3500: train         neg_log_perplexity | -2.99213839\n",
            "Step   3500: train          sequence_accuracy |  0.00000000\n",
            "Step   3500: train weights_per_batch_per_core |  7680.00000000\n",
            "Step   3500: eval                    accuracy |  0.34472659\n",
            "Step   3500: eval                        loss |  2.93830299\n",
            "Step   3500: eval          neg_log_perplexity | -2.93830299\n",
            "Step   3500: eval           sequence_accuracy |  0.00000000\n",
            "Step   3500: eval  weights_per_batch_per_core |  7680.00000000\n",
            "Step   3500: Finished evaluation\n",
            "\n",
            "Step   4000: Ran 500 train steps in 12.49 secs\n",
            "Step   4000: Evaluation\n",
            "Step   4000: train                   accuracy |  0.33990887\n",
            "Step   4000: train                       loss |  2.93956971\n",
            "Step   4000: train         neg_log_perplexity | -2.93956971\n",
            "Step   4000: train          sequence_accuracy |  0.00000000\n",
            "Step   4000: train weights_per_batch_per_core |  7680.00000000\n",
            "Step   4000: eval                    accuracy |  0.35742188\n",
            "Step   4000: eval                        loss |  2.84760427\n",
            "Step   4000: eval          neg_log_perplexity | -2.84760427\n",
            "Step   4000: eval           sequence_accuracy |  0.00000000\n",
            "Step   4000: eval  weights_per_batch_per_core |  7680.00000000\n",
            "Step   4000: Finished evaluation\n",
            "\n",
            "Step   4500: Ran 500 train steps in 12.54 secs\n",
            "Step   4500: Evaluation\n",
            "Step   4500: train                   accuracy |  0.35449219\n",
            "Step   4500: train                       loss |  2.86197305\n",
            "Step   4500: train         neg_log_perplexity | -2.86197305\n",
            "Step   4500: train          sequence_accuracy |  0.00000000\n",
            "Step   4500: train weights_per_batch_per_core |  7680.00000000\n",
            "Step   4500: eval                    accuracy |  0.35657555\n",
            "Step   4500: eval                        loss |  2.81649899\n",
            "Step   4500: eval          neg_log_perplexity | -2.81649899\n",
            "Step   4500: eval           sequence_accuracy |  0.00000000\n",
            "Step   4500: eval  weights_per_batch_per_core |  7680.00000000\n",
            "Step   4500: Finished evaluation\n",
            "\n",
            "Step   5000: Ran 500 train steps in 12.57 secs\n",
            "Step   5000: Evaluation\n",
            "Step   5000: train                   accuracy |  0.33945313\n",
            "Step   5000: train                       loss |  2.89207888\n",
            "Step   5000: train         neg_log_perplexity | -2.89207888\n",
            "Step   5000: train          sequence_accuracy |  0.00000000\n",
            "Step   5000: train weights_per_batch_per_core |  7680.00000000\n",
            "Step   5000: eval                    accuracy |  0.34003907\n",
            "Step   5000: eval                        loss |  2.88922763\n",
            "Step   5000: eval          neg_log_perplexity | -2.88922763\n",
            "Step   5000: eval           sequence_accuracy |  0.00000000\n",
            "Step   5000: eval  weights_per_batch_per_core |  7680.00000000\n",
            "Step   5000: Finished evaluation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrQqLj3r3ibl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def output(input):\n",
        "  predict_model = Chess_transformer_lm(mode='predict')\n",
        "  predict_signature = trax.shapes.ShapeDtype((1,1), dtype=np.int32)\n",
        "  predict_model.init_from_file(os.path.join(output_dir, \"model.pkl.gz\"),weights_only=True, input_signature=predict_signature)\n",
        "  return trax.supervised.decoding.autoregressive_sample(predict_model, input, temperature=0.0, max_length=game_length, eos_id = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX-nvztw6QLa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fullgame(firstmoves):\n",
        "  for i in range(len(firstmoves)):\n",
        "    uci = firstmoves[i]\n",
        "    move = chess.Move.from_uci(uci)\n",
        "    firstmoves[i] = move2token(move)\n",
        "  input = np.array(firstmoves).reshape((1,len(firstmoves)))\n",
        "  played = output(input)\n",
        "  gamestart = input.flatten()\n",
        "  gameplayed = played.flatten()\n",
        "  game = np.concatenate((gamestart,gameplayed))\n",
        "  return game\n",
        "\n",
        "from IPython.core.display import HTML\n",
        "from IPython.display import Javascript\n",
        "\n",
        "def showgame(tokens):\n",
        "  board = chess.Board()\n",
        "  html = ''\n",
        "  for x in tokens:\n",
        "    from_square = x//64\n",
        "    to_square = x % 64\n",
        "    move = chess.Move(from_square,to_square)\n",
        "    if (x == 0):\n",
        "      board.clear()\n",
        "      header = 'Game Over'\n",
        "    else:\n",
        "      legal = move in board.legal_moves\n",
        "      if legal:\n",
        "        legal = 'legal'\n",
        "        style = ''\n",
        "      else:\n",
        "        legal = 'illegal'\n",
        "        style = 'background:red; color:yellow; font-weight:bold;'\n",
        "      header = '<div style=\"'+style+'\">after '+legal+' '+move.uci()+'</div>'\n",
        "      board.push(move)\n",
        "    style = 'display:inline-block; width:20em; text-align:center; margin-bottom: 1em;'\n",
        "    html += '<div style=\"'+style+'\">'+header+chess.svg.board(board)+'</div>'\n",
        "  display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 5000})'''))\n",
        "  display(HTML(html))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vThTDqeUkKxs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# showgame(random_tokenized_game())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX9YB1wYJWuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# showgame(fullgame(['g1h3']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EupWF_AOyRoV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from trax import layers as tl\n",
        "\n",
        "def autoregressive_logits(model, inputs=None,\n",
        "                                 batch_size=1, temperature=1.0,\n",
        "                                 start_id=0, accelerate=True):\n",
        "  if inputs is not None and inputs.shape[0] != batch_size:\n",
        "    raise ValueError(f'Inputs batch size ({inputs.shape[0]}) does not match '\n",
        "                     f'batch_size arg ({batch_size}.')\n",
        "\n",
        "  fast_model = tl.Accelerate(model) if accelerate else model\n",
        "  start_symbol = np.full((batch_size, 1), start_id, dtype=np.int32)\n",
        "  if model.n_in == 1 and inputs is not None:\n",
        "    current_symbols = np.concatenate([start_symbol, inputs], axis=1)\n",
        "  else:\n",
        "    current_symbols = start_symbol\n",
        "\n",
        "  while True:\n",
        "    if model.n_in > 1 and inputs is not None:\n",
        "      logits = fast_model((inputs, current_symbols))[0]\n",
        "    else:\n",
        "      logits = fast_model(current_symbols)\n",
        "    #sample = tl.logsoftmax_sample(logits[:, -1, :], temperature=temperature)\n",
        "    #yield sample\n",
        "    return logits\n",
        "    current_symbols = sample[:, None]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpvF-5K5x45C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def next_token_distribution(input):\n",
        "  predict_model = Chess_transformer_lm(mode='predict')\n",
        "  predict_signature = trax.shapes.ShapeDtype((1,1), dtype=np.int32)\n",
        "  predict_model.init_from_file(os.path.join(output_dir, \"model.pkl.gz\"),weights_only=True, input_signature=predict_signature)\n",
        "  #return trax.supervised.decoding.autoregressive_sample(predict_model, input, temperature=0.0, max_length=game_length, eos_id = 0)\n",
        "  logits = autoregressive_logits(predict_model, input, temperature=0.0)\n",
        "  x = logits[:, -1, :].flatten()\n",
        "  softmax = np.exp(x)/sum(np.exp(x))\n",
        "  return softmax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9XXkDDVA-p7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extend(model,input_tokens_list,length_of_output_tokens_list):\n",
        "  if length_of_output_tokens_list == 0: return input_tokens_list\n",
        "  input = np.array(input_tokens_list).reshape((1,len(input_tokens_list)))\n",
        "  next = next_token_distribution(model,input)\n",
        "  next_token = [np.argmax(next)]\n",
        "  return extend(model,input_tokens_list + next_token,length_of_output_tokens_list-1)\n",
        "\n",
        "def fullgame2(firstmoves):\n",
        "  for i in range(len(firstmoves)):\n",
        "    uci = firstmoves[i]\n",
        "    move = chess.Move.from_uci(uci)\n",
        "    firstmoves[i] = move2token(move)\n",
        "  game = extend(predict_model,firstmoves,8)\n",
        "  return game"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lN3ltV4yUxP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from trax import layers as tl\n",
        "\n",
        "def autoregressive_sample_stream(model, inputs=None,\n",
        "                                 batch_size=1, temperature=1.0,\n",
        "                                 start_id=0, accelerate=True):\n",
        "  if inputs is not None and inputs.shape[0] != batch_size:\n",
        "    raise ValueError(f'Inputs batch size ({inputs.shape[0]}) does not match '\n",
        "                     f'batch_size arg ({batch_size}.')\n",
        "\n",
        "  fast_model = tl.Accelerate(model) if accelerate else model\n",
        "  start_symbol = np.full((batch_size, 1), start_id, dtype=np.int32)\n",
        "  if model.n_in == 1 and inputs is not None:\n",
        "    current_symbols = np.concatenate([start_symbol, inputs], axis=1)\n",
        "  else:\n",
        "    current_symbols = start_symbol\n",
        "\n",
        "  tokens = inputs.flatten()\n",
        "  board = tokens2board(tokens)\n",
        "  display(board)\n",
        "\n",
        "  while True:\n",
        "    if model.n_in > 1 and inputs is not None:\n",
        "      logits = fast_model((inputs, current_symbols))[0]\n",
        "    else:\n",
        "      logits = fast_model(current_symbols)\n",
        "    #sample = tl.logsoftmax_sample(logits[:, -1, :], temperature=temperature)\n",
        "    x = logits[:, -1, :].flatten()\n",
        "    positive = np.exp(x)\n",
        "    legalmoves = board.legal_moves\n",
        "    for x in range(len(positive)):\n",
        "      if token2move(x) not in legalmoves:\n",
        "        positive[x] = 0\n",
        "    next_token = np.argmax(positive)\n",
        "    board.push(token2move(next_token))\n",
        "    sample = next_token\n",
        "    sample = np.array(sample).reshape((1,1))\n",
        "    yield sample\n",
        "    # NOTE: Because the model is autoregressive and in 'predict' mode, its\n",
        "    # history is cached in the model state and the next input is the single\n",
        "    # symbol just sampled.\n",
        "    current_symbols = sample[:, None]\n",
        "\n",
        "\n",
        "def autoregressive_sample(model, inputs=None,\n",
        "                          batch_size=1, temperature=1.0,\n",
        "                          start_id=0, eos_id=1, max_length=100,\n",
        "                          accelerate=True):\n",
        "  result = []\n",
        "  eos_seen = []\n",
        "  counter = 0\n",
        "  for sample in autoregressive_sample_stream(\n",
        "      model, inputs, batch_size=batch_size, temperature=temperature,\n",
        "      start_id=start_id, accelerate=accelerate):\n",
        "    sample = sample[:, None]\n",
        "    result.append(sample)\n",
        "    counter += 1\n",
        "    if counter >= max_length:\n",
        "      return np.concatenate(result, axis=1)\n",
        "    # Check at which batch positions have we already encountered EOS.\n",
        "    for j in range(batch_size):\n",
        "      if int(sample[j, 0]) == eos_id:\n",
        "        eos_seen.append(j)\n",
        "    # If EOS has been seen on all positions, stop.\n",
        "    if all([j in eos_seen for j in range(batch_size)]):\n",
        "      return np.concatenate(result, axis=1)\n",
        "  return np.concatenate(result, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVaxYoFoXGjz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def legal_output(input):\n",
        "  predict_model = Chess_transformer_lm(mode='predict')\n",
        "  predict_signature = trax.shapes.ShapeDtype((1,1), dtype=np.int32)\n",
        "  predict_model.init_from_file(os.path.join(output_dir, \"model.pkl.gz\"),weights_only=True, input_signature=predict_signature)\n",
        "  return autoregressive_sample(predict_model, input, temperature=0.0, max_length=game_length, eos_id = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFlpL8velgu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def full_legalgame(firstmoves):\n",
        "  for i in range(len(firstmoves)):\n",
        "    uci = firstmoves[i]\n",
        "    move = chess.Move.from_uci(uci)\n",
        "    firstmoves[i] = move2token(move)\n",
        "  input = np.array(firstmoves).reshape((1,len(firstmoves)))\n",
        "  played = legal_output(input)\n",
        "  gamestart = input.flatten()\n",
        "  gameplayed = played.flatten()\n",
        "  game = np.concatenate((gamestart,gameplayed))\n",
        "  return game"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s54mS6SOmbBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# showgame(fullgame(['d2d4','f7f5','h2h3']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjC1GJ5fD98_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# showgame(full_legalgame(['e2e4']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyNiJkYFw5uK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def usermove(board):\n",
        "  while True:\n",
        "    print('Type your move in UCI format:')\n",
        "    usermove = input()\n",
        "    move = chess.Move.from_uci(usermove)\n",
        "    if move in board.legal_moves:\n",
        "      return move;\n",
        "    print('You have typed an illegal move.')\n",
        "\n",
        "def legal_token_after_tokens(firstmoves):\n",
        "  input = np.array(firstmoves).reshape((1,len(firstmoves)))\n",
        "  predict_model = Chess_transformer_lm(mode='predict')\n",
        "  predict_signature = trax.shapes.ShapeDtype((1,1), dtype=np.int32)\n",
        "  predict_model.init_from_file(os.path.join(output_dir, \"model.pkl.gz\"),weights_only=True, input_signature=predict_signature)\n",
        "  return autoregressive_sample(predict_model, input, temperature=0.0, max_length=1, eos_id = 0)\n",
        "\n",
        "def playchess():\n",
        "  board = chess.Board()\n",
        "  display(board)\n",
        "  tokens = []\n",
        "  while not board.is_game_over():\n",
        "    move = usermove(board)\n",
        "    board.push(move)\n",
        "    display(board)\n",
        "    tokens.append(move2token(move))\n",
        "    if not board.is_game_over():\n",
        "      token = legal_token_after_tokens(tokens)\n",
        "      token = token.flatten()[0]\n",
        "      tokens.append(token)\n",
        "      move = token2move(token)\n",
        "      board.push(move)\n",
        "      display(board)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3v2R1VGCzhCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "playchess()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}